# Final Work

## LLM Scaling Week 1

### Условие

Ваша задача — **ускорить forward pass функции `swiglu`**:

```python
def swiglu(a, b):
    return torch.nn.functional.silu(a) * b
```

Требуется реализовать версию на **Triton**, которая вызывается через интерфейс:

```python
torch.ops.llm_scaling_week.swiglu_fwd(a, b)
```

Функция должна:

- принимать тензоры `a` и `b` одинаковых типов и размерностей;
- возвращать **один** `torch.Tensor` — результат операции `swiglu(a, b)`.

### Требования к корректности

Результат вашей функции должен совпадать с eager‑имплементацией:

```python
torch.allclose(
    swiglu(a, b),
    torch.ops.llm_scaling_week.swiglu_fwd(a, b)
)
```

Функция должна корректно работать для:

- `fp32`;
- `bf16`.

Входные тензоры гарантированно **contiguous**, размерности могут быть произвольными, решение должно быть эффективным независимо от размерности.

### Требования к производительности

Ваша Triton‑имплементация должна работать **не медленнее, чем 75% от времени eager‑версии**:

```text
time_triton ≤ 0.75 * time_eager
```

### Ограничения

- Время прохождения всех тестов: **до 1 минуты**.

### Система оценивания

- Количество баллов за задачу: **10**.

### Ограничения на количество посылок

- Максимум посылок по задаче: **10**.
- Максимум посылок за скользящие 24 часа: **2**.

### Примечание

- Логи тестирования можно посмотреть, скачав вывод в тесте 1.
- Не переименовывайте файл `solution.py`. Ваше решение должно находиться именно в нём.


---

## LLM Scaling Week 2

### Условие

Условие задачи находится в ноутбуке внутри репозитория (Jupyter Notebook).  
Там описаны:

- постановка задачи;
- интерфейсы для реализации;
- примеры запуска и проверки.

Кратко: задача посвящена **квантованию в `int8` и умножению матриц**.

### Ограничения

- Время прохождения всех тестов: **до 8 минут**.

### Система оценивания

- Количество баллов за задачу: **15**.

### Ограничения на количество посылок

- Максимум посылок по задаче: **10**.
- Максимум посылок за скользящие 24 часа: **2**.

### Важные требования к решению

После того как вы решите задачу, необходимо перенести реализацию следующих функций:

- `quantize_int8_perrow_kernel`
- `quantize_int8`
- `perrow_w8a8_matmul_kernel`
- `matmul_quantize_int8`

в файл `solution.py`.

Внутри этого файла уже определены сигнатуры этих функций — нужно **вставить реализацию вместо `pass`**.

Нельзя:

- переименовывать файл;
- удалять функции;
- добавлять новые функции.

### Примечание

- Логи тестирования можно посмотреть, скачав вывод в тесте 1.


---

## LLM Scaling Week 3

### Задача

Ваша задача — **написать эффективную имплементацию операции `padded_moe_permute`**.

Функция должна называться `submission` и иметь сигнатуру:

```python
def submission(
    x: torch.Tensor,            # (num_tokens, hidden_size) — входной тензор токенов
    top_experts: torch.Tensor,  # (num_tokens, topk) — для каждого токена указано topk экспертов
    tokens_per_expert: torch.Tensor,  # (num_experts,) — сколько токенов приходит к каждому эксперту
    topk: int,                  # сколько экспертов активируется на каждый токен (например, 8)
    num_experts: int,           # всего экспертов в MoE (например, 128)
) -> tuple[
    torch.Tensor,               # (max_padded, hidden_size) — padded_tokens, результат пермьюта с паддингами
    torch.Tensor                # (num_experts,) — padded_tokens_per_expert, батч‑сайзы с учётом паддингов
]:
    ...
```

### Напоминание: обычный `moe_permute` без паддингов

На вход подаётся тензор `x` размерности `(num_tokens, hidden_size)` и `top_experts` размерности `(num_tokens, topk)`.

Пример:

```python
x = tensor([[-0.0236, -0.5368, -0.5663],
            [ 0.7778, -0.8583, -0.1123],
            [ 0.1981, -0.3514, -0.9443],
            [-2.0655, -0.9424,  0.9870]])

top_experts = tensor([[1, 3],  # токен 0 выбирает экспертов 1 и 3
                      [2, 5],  # токен 1 выбирает 2 и 5
                      [3, 5],  # токен 2 выбирает 3 и 5
                      [2, 4]]) # токен 3 выбирает 2 и 4
```

Здесь `topk = 2`.  
Обычно `moe_permute` создаёт тензор размерности `(num_tokens * topk, hidden_size)`, где токены сгруппированы по экспертам:

```python
out = tensor([
    [-0.0236, -0.5368, -0.5663],  # токен 0 -> эксперт 1
    [ 0.7778, -0.8583, -0.1123],  # токен 1 -> эксперт 2
    [-2.0655, -0.9424,  0.9870],  # токен 3 -> эксперт 2
    [-0.0236, -0.5368, -0.5663],  # токен 0 -> эксперт 3
    [ 0.1981, -0.3514, -0.9443],  # токен 2 -> эксперт 3
    [-2.0655, -0.9424,  0.9870],  # токен 3 -> эксперт 4
    [ 0.7778, -0.8583, -0.1123],  # токен 1 -> эксперт 5
    [ 0.1981, -0.3514, -0.9443],  # токен 2 -> эксперт 5
])
```

Батч‑сайзы (число токенов на эксперта) в этом примере:

```text
[1, 2, 2, 1, 2]
```

### Переход к `padded_moe_permute`

Для FP8‑умножения в DeepGEMM (и других современных кернелах) часто нужен **TMA‑alignment**, т.е. размерности должны делиться на 128. В случае `moe_permute` нужно, чтобы **батч‑сайзы экспертов делились на 128**.

Примеры:

- `[1, 2, 2, 1, 2]  →  [128, 128, 128, 128, 128]`
- `[128, 1, 129]    →  [128, 128, 256]`

Чтобы добиться этого, результат пермьюта нужно **дополнить нулевыми токенами (padding)**. Выходной тензор теперь может быть **больше**, чем `num_tokens * topk`.

Требование: первый токен для каждого эксперта должен начинаться с индекса, кратного 128.

Для примера выше результат будет иметь вид (с нулями‑паддингами, показаны фрагменты):

```python
tensor([
    [-0.0236, -0.5368, -0.5663],  # токен 0 -> эксперт 1
    [ 0.0000,  0.0000,  0.0000],
    ...,
    [ 0.7778, -0.8583, -0.1123],  # токен 1 -> эксперт 2, индекс 128
    [-2.0655, -0.9424,  0.9870],  # токен 3 -> эксперт 2, индекс 129
    [ 0.0000,  0.0000,  0.0000],
    ...,
    [ 0.0000,  0.0000,  0.0000],
])
```

### Требования к реализации

- Можно использовать **Triton** или чистый **PyTorch**.
- Будет проверяться:
  - корректность (`torch.allclose` с референсной eager‑версией);
  - производительность (время должно быть **сопоставимо** с референсом).
- В репозитории дан **неэффективный код с `for`‑циклами** — можно использовать его как отправную точку.

### Ограничения

- Время прохождения всех тестов: **до 3 минут**.

### Система оценивания

- Количество баллов за задачу: **25**.

### Ограничения на количество посылок

- Максимум посылок по задаче: **10**.
- Максимум посылок за скользящие 24 часа: **2**.

### Дополнительные замечания

- Логи тестирования можно посмотреть, скачав вывод в тесте 1.
- Не переименовывайте файл `solution.py`; решение должно быть именно в этом файле.
- В `solution.py` есть синтаксическая ошибка в строке 68 — лишняя точка после `torch.Tensor`. В своём решении её нужно убрать.

### История посылок (Week 3)

| Дата и время (МСК) | Вердикт | Язык | Баллы |
|--------------------|---------|------|-------|
| 19.11.25 03:29     | OK      | Ml   | 25    |
| 19.11.25 02:59     | WA      | Ml   | 0     |
| 18.11.25 03:06     | WA      | Ml   | 0     |
| 18.11.25 02:58     | WA      | Ml   | 0     |
| 17.11.25 02:45     | WA      | Ml   | 0     |
| 17.11.25 02:37     | WA      | Ml   | 0     |


---

# Теоретический тест по LLM Scaling

Ниже собраны формулировки вопросов и вариантов ответов (по скриншотам и тексту).

---

## Вопрос 1

**Задача.** Используя данную схему и материалы курса, оцените, сколько времени при идеальных коммуникациях должна занимать сборка в FSDP модели с 235B параметрами, где каждый занимает 2 байта, а параметры шардируются на всех GPU кластера.

> В оригинальном интерфейсе к вопросу прилагалась схема/график.

**Формат ответа:** десятичное число с точкой, **секунды**, точность до двух знаков после запятой.

---

## Вопрос 2

**Задача.** Оцените, сколько времени (в секундах) при оптимальных коммуникациях займёт **upload из CPU RAM в GPU RAM** модели в 50 GB активаций.

**Формат ответа:** десятичное число с точкой, **секунды**, точность до двух знаков после запятой.

---

## Вопрос 3

Скорость HBM: **2.4 TB/s**.  
Скорость GPU в Tensor Core: **800 TFLOPS**.

Оцените время работы функции `forward` в микросекундах (при минимальном времени запуска одного матричного умножения в **10 мкс**):

```python
q = Linear(4096, 8192, device="cuda", dtype=torch.bfloat16)
k = Linear(4096, 512,  device="cuda", dtype=torch.bfloat16)
v = Linear(4096, 512,  device="cuda", dtype=torch.bfloat16)

x = torch.randn(512, 4096, device="cuda", dtype=torch.bfloat16)

def forward(x):
    return q(x), k(x), v(x)

forward(x)
```

**Формат ответа:** натуральное число, **микросекунды**.

---

## Вопрос 4

Скорость HBM: **2.4 TB/s**.  
Скорость GPU в Tensor Core: **800 TFLOPS**.

Оцените время работы функции `forward` в микросекундах (при минимальном времени запуска одного матричного умножения в **10 мкс**):

```python
qkv = Linear(4096, 8192 + 2 * 512, device="cuda", dtype=torch.bfloat16)

x = torch.randn(512, 4096, device="cuda", dtype=torch.bfloat16)

def forward(x):
    return qkv(x)

forward(x)
```

**Формат ответа:** натуральное число, **микросекунды**.

---

## Вопрос 5

Скорость HBM: **2.4 TB/s**.  
Скорость GPU в Tensor Core: **800 TFLOPS**.

Оцените время `forward`:

```python
x = torch.randn(64, 8192, 8192, device="cuda", dtype=torch.bfloat16)
d = torch.sqrt(128)

def forward(x, d):
    return x / d

forward(x, d)
```

**Формат ответа:** натуральное число, **микросекунды**.

---

## Вопрос 6

Скорость HBM: **2.4 TB/s**.  
Скорость GPU в Tensor Core: **800 TFLOPS**.

Оцените время `forward` при оптимальной реализации ядра attention (Flash Attention):

```python
q_seqlen = 16
kv_seq_len = 8192
num_heads = 64
head_dim = 128

q = torch.randn(q_seqlen,  num_heads, head_dim, device="cuda", dtype=torch.bfloat16)
k = torch.randn(kv_seq_len, num_heads, head_dim, device="cuda", dtype=torch.bfloat16)
v = torch.randn(kv_seq_len, num_heads, head_dim, device="cuda", dtype=torch.bfloat16)

out = attention(q, k, v)
```

**Формат ответа:** натуральное число, **микросекунды**.

---

## Вопрос 7

Оптимальная реализация attention из вопроса 6 является:

**Выберите один вариант ответа:**

- Compute bound  
- Memory bound  
- Communication bound  

---

## Вопрос 8

**Скриншот:**

![Вопрос 8 — утилизация attention](sandbox:/mnt/data/3a5761a5-5d65-41f3-9580-9b77cbd24e38.png)

**Формулировка.**  
Что может повысить утилизацию attention из вопроса выше?

(Множественный выбор; в интерфейсе были варианты про увеличение `q_seq_len`, `kv_seq_len` и изменение количества голов `num_heads` для `q`/`kv`.)

---

## Вопрос 9

Сколько SM (Streaming Multiprocessors) можно найти в **H100 SXM**, о которой шла речь в Лекции 3?

**Выберите один вариант ответа:**

- 132  
- 24  
- 520  
- 4  

---

## Вопрос 10

Какая скорость работы с HBM (High‑Bandwidth Memory) заявлена Nvidia в H100 SXM?

**Выберите один вариант ответа:**

- 3.35 TB/s  
- 9 TB/s  
- 15 TB/s  
- 990 GB/s  

---

## Вопрос 11

Какой суммарной вместимостью обладает **L1‑cache / Shared Memory** в одной H100 SXM?

**Выберите один вариант ответа:**

- 33 MB  
- 132 MB  
- 80 GB  
- 128 kB  

---

## Вопрос 12

Пусть мы хотим сложить на GPU два вектора в FP32 и произвести операцию:

\[
c = a + b
\]

В каждом векторе `N` элементов. Сколько байт будут пропущены через память (HBM)?

**Выберите один вариант ответа:**

- `3 N`  
- `4 N`  
- `8 N`  
- `12 N`  

---

## Вопрос 13

Та же операция:

\[
c = a + b
\]

В каждом векторе `N` элементов. Оцените **arithmetic intensity** этой операции.

**Выберите один вариант ответа:**

- `1/12`  
- `1/2`  
- `1`  
- `2/3`  

---

## Вопрос 14

![Вопрос 14 — BF16 vs FP32](sandbox:/mnt/data/9fab80f9-c2c8-42a0-807c-4d61b78ee896.png)

Почему обучение в **BF16** быстрее, чем обучение в **FP32**?  
Выберите **все подходящие варианты**.

Примерные варианты ответа (по скриншоту):

1. Быстрые библиотеки для арифметических операций, такие как `cutlass`, оптимизированы под низкую точность и не так эффективны в FP32.  
2. Внутри GPU есть Tensor Core, который тем быстрее перемножает матрицы, чем меньше разрядность элементов.  
3. Учиться в BF16 «стабильнее», в FP32 много времени уходит на перезапуски упавших экспериментов.  
4. Memory‑bound операции будут меньше замедлять обучение в BF16 (из‑за меньшего объёма данных).  
5. Так как в BF16 меньше бит отведено под экспоненту, то лосс быстрее становится ниже.

---

## Вопрос 15

![Вопрос 15 — сложность FP8](sandbox:/mnt/data/2af01bca-fdfd-419e-9c0d-ae08080b46cb.png)

В чём сложность обучения в **FP8** в сравнении с **BF16**?  
Выберите **все подходящие варианты**.

- Переводить тензор из FP32 в FP8 сложнее, чем из FP32 в BF16.  
- Диапазон чисел, представимый в FP8, значительно меньше диапазона BF16.  
- Точность чисел, представимых в FP8, значительно хуже, чем у BF16.  
- Не все операции можно эффективно реализовать в FP8.

---

## Вопрос 16

![Вопрос 16 — причины замедления на GPU‑кластере](sandbox:/mnt/data/83849cec-3954-425e-97e6-13414b683b82.png)

Выберите причины, по которым может замедляться обучение на GPU‑кластере.  
Укажите **все подходящие варианты**.

- CPU ждёт операций на GPU.  
- Операции, запущенные параллельно, конкурируют за ресурсы.  
- Слишком сильная нагрузка приходится на Tensor Core, коду приходится ждать очереди для обращения к памяти.  
- Кернел часто обращается к HBM (низкая arithmetic intensity, memory‑bound).

---

## Вопрос 17

![Вопрос 17 — swiglu vs swiglu_compiled](sandbox:/mnt/data/aa2aeb92-09d5-4505-8181-087bf8cfd206.png)

Пользуясь `swiglu` и `swiglu_compiled`, измерьте время исполнения этих функций.  
Чему равно отношение `time_compiled / time_eager`?

Фрагмент кода:

```python
import torch
import triton
import torch.nn.functional as F

def swiglu(a, b):
    return F.silu(a) * b

swiglu_compiled = ...  # TODO: your code here
a = torch.randn(128, 128, device="cuda")
b = torch.randn(128, 128, device="cuda")

out = swiglu_compiled(a, b)

time_eager = TODO_BENCH(swiglu(a, b))
time_compiled = TODO_BENCH(swiglu_compiled(a, b))
time_compiled / time_eager
```

**Варианты ответа:**

- 0.3  
- 0.7  
- 1  
- 1.5  

---

## Вопрос 18

![Вопрос 18 — all_gather / all_reduce / reduce](sandbox:/mnt/data/0f9cbc0f-e7d8-46ee-903c-8bc9a0df65ce.png)

Какая операция работает быстрее на 128 хостах из 8 H100 GPU (NVLink/Infiniband) с настройками по умолчанию, если вход — тензор из **одного FP32 элемента**?

**Варианты ответа:**

- `torch.distributed.all_gather_into_tensor(output_tensor, input_tensor)`  
- `torch.distributed.all_reduce(tensor)`  
- `torch.distributed.reduce(tensor, dst=0)`  

---

## Вопрос 19

![Вопрос 19 — reduce_scatter на 4096 GPU](sandbox:/mnt/data/4d4f37cc-7b65-4c7e-aaf6-b48ee8f33b6c.png)

Используя значения эффективных пропускных способностей с графиков, рассчитайте, сколько времени займёт операция **`reduce_scatter`** на **4096 GPU (512 нод)** при использовании HSDP, где:

- размер Sharding Group — 128 GPU;
- размер Replicating Group — 32 GPU;

если размер входного тензора — **512 MiB**.

Уточнения из условия:

- Округляйте пропускную способность с графиков до числа, кратного **50 GB/s**.  
- Считайте, что пропускная способность `reduce_scatter` совпадает с пропускной способностью `all_gather`.  
- Считайте, что если у вас есть 8 независимых пересылок по `<M>` байт на `<N>` хостов, где в каждой пересылке из каждого хоста участвует ровно 1 GPU, то это эквивалентно точке `8 * <M> байт` на графике "`<N> Nodes`".  
- Считайте, что коммуникации по Sharding Group и Replicating Group **не перекрываются**.  
- Учитывайте, что **GiB = 2³⁰ байт**, а GB = 10⁹ байт.  
- Ответ дайте **в миллисекундах** с точностью до **десятых**.

---

## Вопрос 20

![Вопрос 20 — тип данных в reduce_scatter](sandbox:/mnt/data/9b2eec09-356b-42a4-a092-bb9820bd8ace.png)

В операции `reduce_scatter` с использованием алгоритма **ring** и входным **BF16‑тензором**, в каком типе данных происходят пересылки частичных сумм?

**Выберите один вариант ответа:**

- `bf16`  
- `fp32`  

---

_Конец файла._
